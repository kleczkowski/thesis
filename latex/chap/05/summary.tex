\documentclass[../../thesis.tex]{subfiles}

\begin{document}

\chapter{Podsumowanie}

Haskell, mimo eleganckiego i~deklaratywnego stylu programowania,
nie nadaje się do implementacji algorytmów, w~których kluczowa
jest mutowalność oraz czas działania, w~szczególności~są to~algorytmy
kompresji, ale też inne algorytmy strumieniowe ze względu na powolność
mechanizmów użytych do realizacji strumieniowania --- między innymi
wolne monady, czy też czasochłonne dereferowanie obiektów pozostających
jako mutowalne. 

\section{Dalsze rozważania}

Oczywiście, jest to powód do dalszych rozważań na temat przyspieszenia
tego kodu, zachowując odpowiedni poziom ekspresji kodu, jaki został
osiągnięty do tej pory. Haskell posiada wiele narzędzi, które mogą
prowadzić do zoptymalizowania kodu projektu, jak i technik, które
pozwalają je zaimplementować.

Stąd rozważa się dalsze ulepszenia tej pracy, patrząc na słabe punkty tego kodera.

\subsection{Implementacja projektu za pomocą FFI}

Najbardziej trywialnym i pragmatycznym podejściem do problemu jest
implementacja kodera i dekodera w języku C oraz eksportowanie funkcji
odpowiedzialnych za kodowanie danych na zewnątrz, by móc je związać
za pomocą tzw. \emph{Foreign Function Interface}, rozszerzenia kompilatora
GHC, które pozwala na wywoływanie funkcji z języka C, które traktowane 
są jako obce. Oczywiście można zyskać na szybkości rozwiązania,
ponieważ w znaczący sposób omija się użycie odśmiecacza pamięci,
i tym bardziej, nie używa się wewnętrznej pamięci środowiska
czasu wykonywania.

Wadą tego rozwiązania jest to, że mimo pragmatyzmu rozwiązanie nie korzysta
z technik pochodzących w pełni z programowania funkcyjnego.
Ponadto napisanie monadycznego kodu musiałoby się wiązać
z napisaniem przodu obcego kodu, co sprawia, że projekt
rośnie w zbędny kod (ang. \emph{boilerplate}).

\subsection{Inspekcja funkcji operujących na modelu statystycznym}

Podczas profilowania testów obciążeniowych dla projektu napisanego w Haskellu
można zauważyć, że jednym z najbardziej drogim centrum kosztu jest
funkcja~\texttt{query} pochodząca z modułu, który udostępnia
drzewo Fenwicka (nazwane jako \texttt{FreqTree}). 

Ten problem może się wiązać z następującymi powodami:
\begin{itemize}
  \item Funkcja \texttt{mapM} nie jest optymalizowana do rekursji ogonowej,
    przez co \emph{de facto} nie jest kompilowana do pętli. Dzieje się tak,
    ponieważ monada wprowadza dodatkowy kontekst, przez co optymalizacja
    takiej funkcji, która wprowadza rekursję ogonową, nie jest przeprowadzana.
  \item Znaczący procent alokacji w tym centrum kosztu może wiązać się z
    alokacją liczb całkowitych na stercie środowiska czasu uruchomienia
    i natychmiastową ich konsumpcją, przez co wzrasta czas użycia odśmiecacza
    pamięci. Ponieważ jest to problem, który nie wydaje się tak kluczowy
    w skali całego projektu (czas odśmiecania pamięci mieści się co do
    jednego, dwóch rzędów mniej niż czas wykonywania), stąd jego rozwiązywanie
    nie dałoby wymiernych efektów.
\end{itemize}

\subsection{Wariant biblioteki \texttt{pipes} w stylu CPS}

Natomiast spoglądając na najdroższe (prócz funkcji \texttt{main}) centrum kosztu,
funkcję \texttt{lift} możemy przypuszczać co do tego, że biblioteka strumieniująca
nie jest przystosowana do takich zastosowań jak strumieniujące algorytmy
kompresji.

Oczywiście, możnaby zaimplementować bibliotekę \texttt{pipes}
stosując kodowanie Churcha struktury danych za nią stojących.
To mogłoby sprowadzić użycie obiektu strumienia w taki sposób, w którym
operuje się na złożeniach funkcji, a przez to takie rozwiązanie może sprzyjać
fuzji strumieni.
Też wartym zastanowienia się jest implementacja fuzji i oddrzewiania
dla biblioteki do strumieniowania, by móc zaimplementować bardziej
zaawansowane optymalizacje, czy też udostępniać inne już zaimplementowane.

\end{document}
