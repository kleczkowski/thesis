\documentclass[../../praca.tex]{subfiles}

\begin{document}

\chapter{Testy projektu}

\section{Struktura testów porównawczych}

Do testów porównawczych jako próbkę referencyjną
wykorzystano koder arytmetyczny autorstwa \emph{Project Nayuki}
pod licencją MIT. Jego kod źródłowy jest dostępny pod linkiem (dostęp
12 października 2019):

\begin{center}
\verb|https://github.com/nayuki/Reference-arithmetic-coding|
\end{center}

Testy składają się z serii pięciu wykonań nad różnymi przypadkami
testowymi. Spośród wyników wykluczany jest najgorszy i najlepszy
wynik, a z pozostałych trzech wyciągana jest średnia arytmetyczna
(jest to tzw. średnia ścięta).

Wybrano następujące przypadki:
\begin{itemize}
  \item \texttt{pan-tadeusz.txt} --- plik tekstowy zawierający
    ,,Pana Tadeusza'' Adama Mickiewicza jako przypadek, w którym
    testowany jest przypadek średni. Plik pochodzi z Wolnych Lektur,
    jego tekst podlega domenie publicznej, a przypisy i inne
    prace związane z tekstem są powiązane licencją CC-BY-SA 3.0;
  \item \texttt{zeros.1m} --- jednomegabajtowy plik zawierający
    wyłącznie zera, przypadek optymistyczny;
  \item \texttt{random.1m} --- jednomegabajtowy plik zawierający 
    losowe bajty danych pochodzące z \texttt{/dev/random}, który
    reprezentuje kryptograficznie bezpieczny generator pseudolosowy
    o rozkładzie bardzo zbliżonym do jednostajnego, przypadek
    pesymistyczny.
\end{itemize}

\section{Wyniki testów obciążeniowych}

Zgodnie z~powyższą metodologią otrzymano wyniki opisane 
w~tabelach~\ref{tab:encode-time} oraz \ref{tab:decode-time}.

\begin{table}[h]
  \centering
  \begin{tabular}{| l | r | r |}
    \hline
    & C++ & Haskell \\ \hline
    \texttt{pan-tadeusz.txt} & 1,448 s & 8,063 s\\ \hline
    \texttt{zeros.1m} & 2,813 s & 8,380 s\\ \hline
    \texttt{random.1m} & 3,369 s & 24,813 s\\ \hline
  \end{tabular}
  \caption{Średnia obcięta czasu wykonywania operacji kodowania}
  \label{tab:encode-time}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{| l | r | r |}
    \hline
    & C++ & Haskell \\ \hline
    \texttt{pan-tadeusz.txt} & 1,646 s & 11,469 s \\ \hline
    \texttt{zeros.1m} & 3,250 s & 14,656 s\\ \hline
    \texttt{random.1m} & 3,964 s & 33,203 s\\ \hline
  \end{tabular}
  \caption{Średnia obcięta czasu wykonywania operacji dekodowania}
  \label{tab:decode-time}
\end{table}

Należy zauważyć, że testowany koder napisany w Haskellu
jest średnio osiem razy gorszy niż odpowiednia wersja w C++.
Dekodowanie jest szczególnie wolniejsze oraz wrażliwsze 
na rodzaj przekazywanych danych, co ma powiązanie z 
średnim czasem dostępu do tablicy, która przechowuje
sumy prefiksowe częstotliwości symboli. Średni czas
dekodera napisanego w Haskellu jest od około sześciu 
do jedenastu razy gorszy od próby referencyjnej.

\begin{table}[h]
  \centering
  \subfloat[Entropia]{
    \begin{tabular}{|l|l|l|l|}
      \hline
      $ $ & Oryginał & Po kompresji (C++) & Po kompresji (Haskell) \\ \hline
      \texttt{pan-tadeusz.txt} & 5,0818 & 7,9994 & 7,9994 \\ \hline
      \texttt{random.1m} & 7,9998 & 7,9998 & 7,9998 \\ \hline
      \texttt{zeros.1m} & 0,0000 & 0,0944 & 0,0707 \\ \hline
    \end{tabular}
  }
  \quad
  \subfloat[Rozmiar plików i stopień kompresji dla Haskella]{
    \begin{tabular}{|l|l|l|l|}
      \hline
      $ $ & Oryginał (bajty) & Po kompresji (bajty) & Stopień kompresji \\ \hline
      \texttt{pan-tadeusz.txt} & 493 451 & 313 759 & 1,5677 \\ \hline
      \texttt{random.1m} & 1 048 576 & 1 049 720 & 0,9989  \\ \hline
      \texttt{zeros.1m} & 1 048 576 & 4293 & 244,25 \\ \hline
    \end{tabular}
  }
  \quad
  \subfloat[Rozmiar plików i stopień kompresji dla C++]{
    \begin{tabular}{|l|l|l|l|}
      \hline
      $ $ & Oryginał (bajty) & Po kompresji (bajty) & Stopień kompresji \\ \hline
      \texttt{pan-tadeusz.txt} & 493 451 & 313 782 & 1,5726 \\ \hline
      \texttt{random.1m} & 1 048 576 & 1 048 753 & 0,9998  \\ \hline
      \texttt{zeros.1m} & 1 048 576 & 432 & 2427,2 \\ \hline
    \end{tabular}
  }
  \caption{Wybrane wskaźniki kompresji}
  \label{tab:quality-of-compress}
\end{table}

Tabele~\ref{tab:quality-of-compress} potwierdzają, iż napisany projekt działa poprawnie.
Obserwujemy podobny stopień kompresji oraz entropię zakodowanego pliku w obu projektach.
Jedyną różnicą jest stopień kompresji dla przypadku testowego \texttt{zeros.1m}.

Wyniki różnią się o jeden rząd, ponieważ implementacja w C++ nie aktualizuje
ciągle modelu statystycznego --- jest on aktualizowany co 16 kilobajtów. 
Implementacja w Haskellu zakłada ciągłą aktualizację modelu, przez co
otrzymujemy dodatkowe bity na wyjściu.

\end{document}
